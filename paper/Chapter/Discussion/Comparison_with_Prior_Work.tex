The proposed lightweight pose estimator can be contrasted against several state-of-the-art approaches. High-Resolution Net (HRNet) maintains high-resolution feature maps throughout the network, enabling precise keypoint localization at the cost of a large model size and computational load. Even a trimmed efficient HRNet variant achieved over 67\% AP on COCO keypoints by preserving multi-scale feature fusion and using attention modules to compensate for reduced depth \cite{Sun_2019_CVPR}. In contrast, our CSPNet backbone, while compact, lacked such rich representation and was trained from scratch rather than fine-tuned from pretrained weights.

MobileNetV3-based pose networks have demonstrated that an ImageNet-pretrained MobileNetV3 backbone combined with a lightweight keypoint head can reach around 65\% AP on COCO test-dev at real-time speeds \cite{Howard2017}. These successes critically depend on transfer learning, which provides a strong initialization for the backbone. Our model, by comparison, initialized all weights randomly, placing it at a significant disadvantage in feature quality and convergence speed.

The Lightweight Pose Network (LPN) uses depthwise separable convolutions and channel attention in a ResNet-like backbone, together with a specialized \emph{Beta Soft-Argmax} decoding strategy, to achieve 68.7\% AP on COCO with only 2.7M parameters \cite{Zhang2020LPN}. LPNâ€™s multi-stage training and iterative refinement were key to its success. By contrast, our one-stage training lacked progressive refinement, leaving the small model unable to learn robust pose features.

Finally, the use of knowledge distillation has been shown to transfer the accuracy of large teacher models into small student models for pose estimation \cite{Li2021OKD}. We did not employ any distillation or teacher-student strategy, further widening the performance gap.
