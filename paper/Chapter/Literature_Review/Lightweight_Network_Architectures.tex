Another line of research focuses on designing compact CNN architectures that serve as efficient backbones for pose estimation. These lightweight networks drastically reduce the number of parameters and operations, making real-time pose estimation on mobile or embedded devices feasible. MobileNet \citep{Howard2017} pioneered the use of depthwise separable convolutions to shrink model size and complexity, demonstrating that a streamlined network can still achieve reasonable accuracy. ShuffleNet \citep{Zhang2018} introduced pointwise group convolution and channel shuffling to further improve efficiency, allowing convolutional layers to split and shuffle feature channels for better information flow at low cost. EfficientNet \citep{Tan2019} took a principled approach to scaling CNN width, depth, and resolution, yielding a family of models that optimize accuracy per FLOP via compound scaling. More recent architectures such as GhostNet \citep{Han2020} generate additional “ghost” feature maps from cheap linear operations to reduce redundancy, and CSPNet \citep{Wang2020CSPNet} (Cross-Stage Partial Network) splits feature computation across network stages to lighten the backbone while preserving learning capability.

These compact backbones have been adopted in pose estimation frameworks to create lightweight pose networks. By replacing a heavy backbone (like ResNet or HRNet) with a MobileNet or ShuffleNet, one can dramatically lower computation and model size, enabling faster inference on CPUs or mobile GPUs \citep{Osokin2018}. For instance, OpenPose and other multi-person models have published faster variants using MobileNet as the feature extractor, trading off some accuracy for real-time speed. Similarly, EfficientNet-based and GhostNet-based backbones have been explored in recent pose detectors to minimize latency. In general, the use of these efficient architectures helps reduce the resource requirements of pose estimation, albeit often with a modest drop in keypoint precision. Ongoing research seeks to balance this trade-off, sometimes by fine-tuning or modifying the backbone (e.g. adding attention or multi-scale features) to regain accuracy while retaining low complexity.
