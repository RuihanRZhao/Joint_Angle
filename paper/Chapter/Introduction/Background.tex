Human pose estimation (HPE) aims to locate a set of anatomical keypoints (e.g.\ joints) on the human body from images or video. Early methods treated this as a graphical model problem, using hand-crafted features and part-based models. A seminal approach is the pictorial structures framework, which represents each limb as a deformable part connected in a tree and infers joint locations by optimizing pairwise spatial relationships \citep{Felzenszwalb2005}. While effective in controlled settings, these classical methods struggled with the high variability of real-world poses, occlusions, and complex backgrounds.

The introduction of deep learning dramatically advanced HPE accuracy. Toshev and Szegedy \citep{Toshev2014} proposed \emph{DeepPose}, the first end-to-end convolutional network to directly regress joint coordinates. Subsequent works reframed pose estimation as dense heatmap prediction, yielding substantial gains. Convolutional Pose Machines \citep{Wei2016} introduced a multi-stage architecture that refines heatmap predictions iteratively, and the Stacked Hourglass Network \citep{Newell2016} employed a symmetric encoder–decoder to capture and fuse multi-scale information. More recently, High-Resolution Networks (HRNet) maintain high-resolution feature streams and achieve state-of-the-art accuracy by repeatedly exchanging information across scales \citep{Sun_2019_CVPR}. These deep models now surpass traditional approaches by wide margins on benchmarks such as MPII and COCO \citep{Lan2023}.

Extending to multi-person scenarios, HPE methods follow either a \emph{top-down} or \emph{bottom-up} paradigm. Top-down methods first detect each person with a bounding-box detector and then apply a single-person pose estimator to each crop (e.g.\ Mask R-CNN with a keypoint head) \citep{He2017}. This yields high per-person accuracy but incurs linear cost in the number of people. Bottom-up methods, exemplified by OpenPose \citep{Cao_2017_CVPR}, detect all keypoints in one pass and then assemble them into individual skeletons via part affinity fields. Bottom-up pipelines have runtime largely independent of person count, making them attractive for crowded or real-time settings, though they often lag slightly behind top-down methods in raw accuracy \citep{Dubey2023PoseSurvey}.

Despite their success, these deep networks tend to be large and computationally expensive. For instance, HRNet-W48 has over 60 million parameters, and OpenPose’s original model requires tens of GFLOPs per frame. Such complexity hinders deployment on edge devices (e.g.\ mobile phones, embedded cameras) where memory, compute, and power are limited. To address this, recent research has focused on \emph{lightweight} HPE architectures and compression techniques. Osokin \citep{Osokin2018} presented a “Lightweight OpenPose” with only 4.1M parameters, achieving real-time CPU inference by pruning and replacing expensive layers. Other works explore network pruning, quantization, and knowledge distillation to compress pose models without severe accuracy loss \citep{Lan2023}. These efforts demonstrate that redundancy in large pose networks can be reduced substantially, but balancing accuracy and efficiency remains an open challenge.

Moreover, applications such as mobile fitness tracking, augmented reality, and human–robot interaction increasingly demand on-device HPE to ensure low latency, privacy, and offline operation. Consequently, there is a pressing need for methods that deliver competitive pose estimation accuracy while operating within the strict resource budgets of edge hardware. This thesis investigates one such approach by combining an efficient backbone (CSPNet), compact attention modules (SE), and a streamlined coordinate classification head (SimCC) to push the frontier of lightweight, edge-ready human pose estimation.