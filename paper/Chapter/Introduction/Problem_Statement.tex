The goal of this thesis is to design and evaluate a compact, efficient human pose estimation model suitable for real-time deployment on resource-constrained devices. In particular, we target a 2D pose estimator that can run on edge hardware (such as mobile or embedded platforms) with limited computational power, without offloading to powerful GPUs or cloud servers. The research question can be summarized as: How can we achieve high-accuracy human pose estimation with a lightweight model architecture that meets the speed and memory constraints of edge devices?

To address this problem, our approach integrates several techniques aimed at reducing network complexity while preserving accuracy. First, we adopt a Cross Stage Partial Network (CSPNet) architecture for the backbone feature extractor \citep{Wang2020CSPNet}. CSPNet is a design that partitions feature maps at each stage of the network into two parts – one part undergoes computation in the next layer while the other bypasses it – and then merges them. This effectively reduces duplicate gradient computations and allows a deep network to be thinner (fewer channels) without losing representational power. By incorporating CSPNet ideas into the pose model’s backbone, we aim to lower the number of parameters and FLOPs required for feature learning, which directly tackles the efficiency goal.

Second, we enhance the backbone with Squeeze-and-Excitation (SE) attention modules \citep{Hu2018SENet}. SE blocks perform a lightweight form of channel-wise attention by learning to reweight the feature channels according to their importance. This mechanism can improve the network’s feature quality and boost accuracy with only a modest increase in parameters. In a compact model, making the most of each channel is crucial; SE helps the network focus on informative features (for example, those corresponding to keypoint locations or human limb patterns) while suppressing less useful feature responses. We hypothesize that adding SE units will allow us to trim the model size further (since the remaining channels become more expressive) without sacrificing accuracy.

Third, our model employs a recently proposed keypoint representation called SimCC (Simple Coordinate Classification) \citep{Li2022SimCC}. Traditional pose estimators predict heatmaps on a high-resolution output grid (e.g. $64\times64$ or $128\times128$ per keypoint) and then find the maximum – this process is both memory- and compute-intensive due to the upsampling and large heatmap tensors. SimCC offers an alternative by reformulating pose estimation as two independent classification tasks for the $x$ and $y$ coordinates of each joint. In practice, the network produces probability distributions over possible $x$ positions and $y$ positions (within the image frame) instead of dense 2D heatmaps. This discretized coordinate classification achieves sub-pixel localization accuracy while avoiding the need for transpose convolutions or large output layers for heatmaps \citep{Li2022SimCC}. By using SimCC in our model’s keypoint head, we expect to significantly reduce the computation in the output stage and eliminate post-processing steps, thus streamlining the overall pipeline.

In summary, the project’s objective is to develop a pose estimation model that fuses these components – a CSPNet-based efficient backbone, SE attention modules, and a SimCC keypoint prediction head – to deliver high accuracy with low computational cost. We will measure success in terms of model size (parameter count), speed (inferences per second on a given device), and accuracy on standard pose benchmarks. The ideal outcome is a trained model that approaches the accuracy of state-of-the-art models on datasets like COCO, while being small and fast enough to run in real-time on a typical edge device. This would demonstrate a viable solution for real-world deployments of human pose estimation in scenarios where computing resources are limited.
