import os
import time
import numpy as np
from PIL import Image
import zipfile
from tqdm import tqdm
import requests

import torch
from torch.utils.data import Dataset
from torchvision import transforms

from pycocotools.coco import COCO

from .encoder_decoder import keypoints_to_heatmaps

class COCOPoseDataset(Dataset):
    """Custom Dataset for COCO keypoint data (single-person)."""
    def __init__(self,
                 root,
                 ann_file,
                 img_dir,
                 input_size=(384, 216),
                 transform=None,
                 return_meta=False,
                 max_samples=None  # æ–°å¢ï¼šæœ€å¤§æ ·æœ¬æ•°é‡ä¸Šé™
                 ):
        """
        ann_file: path to COCO keypoints annotation JSON (e.g., person_keypoints_train2017.json)
        img_dir: directory containing the images (e.g., train2017 folder)
        input_size: (input_h, input_w), size to which images are cropped and resized.
        transform: optional torchvision transforms to apply to the image.
        return_meta: if True, __getitem__ returns (image_tensor, meta) instead of training targets.
        max_samples: if provided, limit the dataset to the first max_samples annotations.
        """
        self.coco = COCO(os.path.join(root, ann_file))
        self.img_dir = os.path.join(root, img_dir)
        self.input_size = input_size  # (input_w, input_h) or (input_h, input_w) based on usage
        self.transform = transform
        self.return_meta = return_meta

        # Load all person annotations
        self.annotations = []
        ann_ids = self.coco.getAnnIds(catIds=[1])  # category 1 is person
        for ann_id in ann_ids:
            ann = self.coco.loadAnns(ann_id)[0]
            # Filter out annotations with no keypoints (num_keypoints == 0)
            if ann.get('num_keypoints', 0) > 0 and np.any(np.array(ann['keypoints'], dtype=np.float32) > 0):
                self.annotations.append(ann)
        # Sort annotations by image_id for consistency
        self.annotations.sort(key=lambda x: x['image_id'])
        if max_samples is not None:
            self.annotations = self.annotations[:max_samples]

    def __getitem__(self, idx):
        # Load annotation and corresponding image
        ann = self.annotations[idx]
        image_info = self.coco.loadImgs(ann['image_id'])[0]
        img_path = os.path.join(self.img_dir, image_info['file_name'])
        # Open image
        img = Image.open(img_path).convert('RGB')
        # Keypoints and bounding box from annotation
        keypoints = np.array(ann['keypoints'], dtype=np.float32).reshape(-1, 3)
        bbox = ann.get('bbox', None)  # [x, y, w, h]
        if bbox is None:
            # If no bbox provided, compute from keypoints as min/max (not typical for COCO)
            visible_pts = keypoints[keypoints[:, 2] > 0]
            if visible_pts.size == 0:
                visible_pts = keypoints[:, :2]  # no visible keypoints, take all (could be zeroes)
            x_min, y_min = visible_pts[:, 0].min(), visible_pts[:, 1].min()
            x_max, y_max = visible_pts[:, 0].max(), visible_pts[:, 1].max()
            bbox = [float(x_min), float(y_min), float(x_max - x_min), float(y_max - y_min)]
        x, y, w, h = bbox
        # Optionally expand the bounding box slightly for more context
        pad = 0.15  # 15% padding
        x_c, y_c = x + w / 2.0, y + h / 2.0
        w = w * (1 + pad)
        h = h * (1 + pad)
        x = x_c - w / 2.0
        y = y_c - h / 2.0
        # Clamp the coordinates to be within image bounds
        img_width, img_height = img.size
        x = max(0, x)
        y = max(0, y)
        w = min(w, img_width - x)
        h = min(h, img_height - y)
        # Crop and resize the image to the input size
        crop_box = (int(x), int(y), int(x + w), int(y + h))
        img_crop = img.crop(crop_box)
        input_w, input_h = self.input_size
        # Preserve aspect ratio by padding if needed:
        # Compute aspect ratios
        orig_w, orig_h = img_crop.size
        target_ratio = input_w / input_h
        orig_ratio = orig_w / orig_h if orig_h != 0 else target_ratio
        if abs(orig_ratio - target_ratio) < 1e-6:
            # If aspect ratio is essentially the same, just resize directly
            img_resized = img_crop.resize((input_w, input_h), Image.BILINEAR)
            pad_left = pad_top = pad_right = pad_bottom = 0
        else:
            # Determine scale to fit within target while preserving aspect
            scale = min(input_w / orig_w, input_h / orig_h)
            new_w = int(orig_w * scale)
            new_h = int(orig_h * scale)
            img_scaled = img_crop.resize((new_w, new_h), Image.BILINEAR)
            # Create new image with black background
            img_resized = Image.new('RGB', (input_w, input_h))
            # paste scaled image at top-left corner (not centered)
            img_resized.paste(img_scaled, (0, 0))
            pad_left = pad_top = 0
            pad_right = input_w - new_w
            pad_bottom = input_h - new_h
        # Apply image transformations (to tensor and normalization)
        if self.transform:
            img_tensor = self.transform(img_resized)
        else:
            img_tensor = transforms.ToTensor()(img_resized)  # convert to [0,1] float tensor
            img_tensor = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                              std=[0.229, 0.224, 0.225])(img_tensor)
        # If return_meta, skip target generation and return metadata
        if self.return_meta:
            # Use the augmented (padded/clamped) bounding box as meta
            meta_bbox = np.array([x, y, w, h], dtype=np.float32)
            meta = {
                'image_id': ann['image_id'],
                'bbox': meta_bbox
            }
            return img_tensor, meta
        # Otherwise, generate target heatmaps and mask
        # Adjust keypoints coordinates to cropped & resized image space
        keypoints[:, 0] -= x
        keypoints[:, 1] -= y
        # ç¡®å®šå…³é”®ç‚¹ç¼©æ”¾æ¯”ä¾‹ï¼ˆæ ¹æ®æ˜¯å¦ä¿æŒçºµæ¨ªæ¯”ï¼‰ ğŸ“
        if pad_right != 0 or pad_bottom != 0:
            # ä¿æŒçºµæ¨ªæ¯”çš„ç¼©æ”¾ï¼Œä½¿ç”¨å®é™…ç¼©æ”¾å°ºå¯¸è®¡ç®—scale ğŸ“
            scale_x = (input_w - pad_right) / (w if w != 0 else 1)
            scale_y = (input_h - pad_bottom) / (h if h != 0 else 1)
        else:
            # æœªä½¿ç”¨paddingï¼ˆé•¿å®½æ¯”ä¸ç›®æ ‡ä¸€è‡´ï¼‰ï¼ŒæŒ‰ç›´æ¥ç¼©æ”¾è®¡ç®—scale ğŸ“
            scale_x = input_w / (w if w != 0 else 1)
            scale_y = input_h / (h if h != 0 else 1)
        keypoints[:, 0] *= scale_x
        keypoints[:, 1] *= scale_y

        keypoints[:, 0] += pad_left
        keypoints[:, 1] += pad_top

        keypoints_pixel = keypoints.copy()

        keypoints[:, 0] = keypoints[:, 0] / (input_w - 1) * 2 - 1   # å½’ä¸€åŒ–åˆ°[-1,1]
        keypoints[:, 1] = keypoints[:, 1] / (input_h - 1) * 2 - 1

        # ç”Ÿæˆç›®æ ‡çƒ­å›¾å’Œ maskï¼ˆçƒ­å›¾å¤§å°ä¸ºè¾“å…¥çš„ 1/4ï¼‰
        out_w = input_w // 4
        out_h = input_h // 4
        target_heatmaps = keypoints_to_heatmaps(keypoints_pixel, input_size=(input_h, input_w),
                                                output_size=(out_h, out_w), sigma=2)
        # mask: 1 for visible joints, 0 for invisible
        mask = np.where(keypoints[:, 2] > 0, 1.0, 0.0).astype(np.float32)

        target_heatmaps_tensor = torch.from_numpy(target_heatmaps).to(dtype=torch.float32)
        keypoints_tensor = torch.from_numpy(keypoints[:, :2]).to(dtype=torch.float32)
        mask_tensor = torch.from_numpy(mask).to(dtype=torch.float32)
        return img_tensor, target_heatmaps_tensor, keypoints_tensor, mask_tensor


    def __len__(self):
        return len(self.annotations)


def ensure_coco_data(root, retries: int = 3, backoff_factor: float = 2.0):
    """
    ç¡®ä¿ root ä¸‹å­˜åœ¨ COCO 2017 çš„ train/val å›¾åƒå’Œæ³¨è§£ã€‚
    å¦‚æœç¼ºå¤±ï¼Œåˆ™ä»å®˜æ–¹ URL ä¸‹è½½å¹¶è§£å‹ã€‚
    æ”¯æŒé‡è¯•æœºåˆ¶å’Œå‹å¥½æç¤ºã€‚

    Args:
        root (str): æ•°æ®æ ¹ç›®å½•ï¼Œæ¯”å¦‚ "data/coco"
        retries (int): æœ€å¤šé‡è¯•æ¬¡æ•°
        backoff_factor (float): æ¯æ¬¡é‡è¯•ç­‰å¾…æ—¶é—´çš„å¢é•¿å› å­
    Raises:
        RuntimeError: ä¸‹è½½æˆ–è§£å‹å¤šæ¬¡å¤±è´¥åæŠ›å‡º
    """
    os.makedirs(root, exist_ok=True)

    # COCO å®˜æ–¹ä¸‹è½½é“¾æ¥
    urls = {
        "train2017.zip":   "http://images.cocodataset.org/zips/train2017.zip",
        "val2017.zip":     "http://images.cocodataset.org/zips/val2017.zip",
        "annotations.zip": "http://images.cocodataset.org/annotations/annotations_trainval2017.zip",
    }

    for fname, url in urls.items():
        zip_path = os.path.join(root, fname)
        target_folder = {
            "train2017.zip":   os.path.join(root, "train2017"),
            "val2017.zip":     os.path.join(root, "val2017"),
            "annotations.zip": os.path.join(root, "annotations"),
        }[fname]

        # å¦‚æœæ–‡ä»¶å¤¹å·²ç»å­˜åœ¨ï¼Œåˆ™è·³è¿‡
        if os.path.isdir(target_folder):
            continue

        # å¦åˆ™ï¼Œéœ€è¦ä¸‹è½½å¹¶è§£å‹
        for attempt in range(1, retries + 1):
            try:
                print(f"[COCO] ç¬¬ {attempt} æ¬¡å°è¯•ä¸‹è½½ {fname} ...")
                resp = requests.get(url, stream=True, timeout=10)
                resp.raise_for_status()

                # å†™å…¥æœ¬åœ° zip
                total = int(resp.headers.get('content-length', 0))
                with open(zip_path, 'wb') as f, tqdm(
                    desc=f"Downloading {fname}",
                    total=total,
                    unit='B',
                    unit_scale=True
                ) as pbar:
                    for chunk in resp.iter_content(chunk_size=1024 * 1024):
                        if chunk:
                            f.write(chunk)
                            pbar.update(len(chunk))

                # æˆåŠŸä¸‹è½½ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                break

            except requests.exceptions.RequestException as e:
                print(f"[COCO] ä¸‹è½½å¤±è´¥ï¼ˆ{e}ï¼‰")
                if attempt < retries:
                    wait = backoff_factor ** (attempt - 1)
                    print(f"[COCO] {wait:.1f}s åé‡è¯•â€¦")
                    time.sleep(wait)
                else:
                    raise RuntimeError(f"å¤šæ¬¡ä¸‹è½½ {fname} å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æ‰‹åŠ¨ä¸‹è½½å®‰è£…ï¼š{url}")

        # è§£å‹ zip
        print(f"[COCO] è§£å‹ {zip_path} â†’ {target_folder}")
        try:
            with zipfile.ZipFile(zip_path, 'r') as z:
                # è·å–æ‰€æœ‰æ–‡ä»¶çš„åˆ—è¡¨
                file_list = z.namelist()

                # ä½¿ç”¨tqdmæ˜¾ç¤ºè§£å‹è¿›åº¦
                with tqdm(total=len(file_list), desc="Unzipping", unit="file") as pbar:
                    for file in file_list:
                        z.extract(file, root)
                        pbar.update(1)

        except zipfile.BadZipFile as e:
            raise RuntimeError(f"è§£å‹ {zip_path} å¤±è´¥ï¼š{e}")
